{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kymberly Ayodeji: Solution code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/codio/.local/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codio/.local/lib/python3.6/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (6.7)\n",
      "Requirement already satisfied: tqdm in /home/codio/.local/lib/python3.6/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/codio/.local/lib/python3.6/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources in /home/codio/.local/lib/python3.6/site-packages (from tqdm->nltk) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm->nltk) (3.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: TextBlob in /home/codio/.local/lib/python3.6/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/codio/.local/lib/python3.6/site-packages (from TextBlob) (3.6.7)\n",
      "Requirement already satisfied: joblib in /home/codio/.local/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codio/.local/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (2023.6.3)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.1->TextBlob) (6.7)\n",
      "Requirement already satisfied: tqdm in /home/codio/.local/lib/python3.6/site-packages (from nltk>=3.1->TextBlob) (4.64.1)\n",
      "Requirement already satisfied: importlib-resources in /home/codio/.local/lib/python3.6/site-packages (from tqdm->nltk>=3.1->TextBlob) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm->nltk>=3.1->TextBlob) (3.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Beautifulsoup4 in /usr/lib/python3/dist-packages (4.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: googletrans==4.0.0-rc1 in /home/codio/.local/lib/python3.6/site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in /home/codio/.local/lib/python3.6/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: sniffio in /home/codio/.local/lib/python3.6/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2018.1.18)\n",
      "Requirement already satisfied: idna==2.* in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.6)\n",
      "Requirement already satisfied: httpcore==0.9.* in /home/codio/.local/lib/python3.6/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /home/codio/.local/lib/python3.6/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: chardet==3.* in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: hstspreload in /home/codio/.local/lib/python3.6/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
      "Requirement already satisfied: h2==3.* in /home/codio/.local/lib/python3.6/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /home/codio/.local/lib/python3.6/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: contextvars>=2.1 in /home/codio/.local/lib/python3.6/site-packages (from sniffio->httpx==0.13.3->googletrans==4.0.0-rc1) (2.4)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /home/codio/.local/lib/python3.6/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /home/codio/.local/lib/python3.6/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/codio/.local/lib/python3.6/site-packages (from contextvars>=2.1->sniffio->httpx==0.13.3->googletrans==4.0.0-rc1) (0.19)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from immutables>=0.9->contextvars>=2.1->sniffio->httpx==0.13.3->googletrans==4.0.0-rc1) (4.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/codio/.local/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: tqdm in /home/codio/.local/lib/python3.6/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (6.7)\n",
      "Requirement already satisfied: joblib in /home/codio/.local/lib/python3.6/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codio/.local/lib/python3.6/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: importlib-resources in /home/codio/.local/lib/python3.6/site-packages (from tqdm->nltk) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from importlib-resources->tqdm->nltk) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    " # Install Necessary resources \n",
    "!pip install nltk\n",
    "!pip install TextBlob\n",
    "!pip install Beautifulsoup4\n",
    "!pip install googletrans==4.0.0-rc1\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Needed Libraries and Necessary resources from NLTK, Beautiful Soup, TextBlob, Google Translate\n",
    "import html5lib\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from googletrans import Translator \n",
    "import os\n",
    "import sqlite3 as sql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a) Fetch Financial News headlines\n",
    "cnbc_URL = \"https://www.cnbc.com/stocks/\"\n",
    "cnbc_headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "cnbc_r = requests.get(cnbc_URL, headers=cnbc_headers)\n",
    "cnbc_timestamp=datetime.now()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b)Fetch Stock Market Data \n",
    "aapl_url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=AAPL&interval=60min&outputsize=compact&apikey=LJ7H7F9D9Z7ECUK7&datatype=csv'\n",
    "r_aapl=requests.get(aapl_url)\n",
    "msft_url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=MSFT&interval=60min&outputsize=compact&apikey=LJ7H7F9D9Z7ECUK7&datatype=csv'\n",
    "r_msft=requests.get(msft_url)\n",
    "goog_url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=GOOG&interval=60min&outputsize=compact&apikey=LJ7H7F9D9Z7ECUK7&datatype=csv'\n",
    "r_goog=requests.get(goog_url)\n",
    "amzn_url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=AMZN&interval=60min&outputsize=compact&apikey=LJ7H7F9D9Z7ECUK7&datatype=csv'\n",
    "r_amzn=requests.get(amzn_url)\n",
    "meta_url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=META&interval=60min&outputsize=compact&apikey=LJ7H7F9D9Z7ECUK7&datatype=csv'\n",
    "r_meta=requests.get(meta_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a, 2b, 2c, 2d: Financial News Headline Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the extracted Financial News headline data, retrieve the url for the headline\n",
    "html_text = cnbc_r.text\n",
    "soup = BeautifulSoup(html_text, 'lxml')\n",
    "card_titles=soup.find_all('a', class_='Card-title')\n",
    "headlines_data=[]\n",
    "for title in card_titles:\n",
    "    headlines_data.append(title['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title from url and strip .html then create a list of sentences for each url \n",
    "df_holder=pd.DataFrame(headlines_data, columns=['url'])\n",
    "df_holder[['http','empty', 'site', 'year','month','date','title']] = df_holder.url.str.split(\"/\",expand=True)\n",
    "titles=df_holder['title'].str.replace('-', ' ').tolist()\n",
    "sentences =  [x[:-4] for x in titles]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data frame for the headlines and add the columns for title, url, timestamp\n",
    "df_headlines=pd.DataFrame(sentences, columns=['headline'])\n",
    "df_headlines['url']=df_holder['url']\n",
    "df_headlines['timestamp'] = cnbc_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a. Add the sentiment score and sentiment for each headline sentence using the toekenize functions\n",
    "df_headlines['sentiment_score']=df_headlines['headline'].apply(lambda sent: TextBlob(sent).sentiment.polarity)\n",
    "def f(score):\n",
    "    if -1 <= score  and score < -0.2: return \"negative\"\n",
    "    elif -0.2 <= score and score > 0.2: return \"neutral\" \n",
    "    else: return \"positive\"\n",
    "assign_sentiment = lambda x: list(map(f, x))\n",
    "df_headlines['sentiment']=assign_sentiment(df_headlines['sentiment_score'])\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b. Tokenize the text into individual \"relevant words\" by NLTK\n",
    "df_headlines['relevant_words']=df_headlines['headline'].apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2c. Create new translated column\n",
    "my_translator = Translator()\n",
    "df_headlines['headline_es']=df_headlines['headline'].apply(lambda x: my_translator.translate(x, src='en', dest='es').text)\n",
    "df_headlines['headline_it']=df_headlines['headline'].apply(lambda x: my_translator.translate(x, src='en', dest='it').text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>relevant_words</th>\n",
       "      <th>headline_es</th>\n",
       "      <th>headline_it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta is the most overbought stock on wall str...</td>\n",
       "      <td>https://www.cnbc.com/2023/06/18/delta-is-the-m...</td>\n",
       "      <td>2023-06-18 22:12:00.557919</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[delta, is, the, most, overbought, stock, on, ...</td>\n",
       "      <td>Delta es el stock más exagerado en Wall Street...</td>\n",
       "      <td>Delta è lo stock più comprovato di Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this compact fund beats the market and provide...</td>\n",
       "      <td>https://www.cnbc.com/2023/06/18/this-compact-f...</td>\n",
       "      <td>2023-06-18 22:12:00.557919</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>negative</td>\n",
       "      <td>[this, compact, fund, beats, the, market, and,...</td>\n",
       "      <td>Este fondo compacto supera al mercado y propor...</td>\n",
       "      <td>Questo fondo compatto batte il mercato e forni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blinken meets chinese foreign minister qin gan...</td>\n",
       "      <td>https://www.cnbc.com/2023/06/18/blinken-meets-...</td>\n",
       "      <td>2023-06-18 22:12:00.557919</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>positive</td>\n",
       "      <td>[blinken, meets, chinese, foreign, minister, q...</td>\n",
       "      <td>Blinken se reúne con el ministro de Relaciones...</td>\n",
       "      <td>Blinken incontra il ministro degli Esteri cine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the japanese equity rally could broaden out so...</td>\n",
       "      <td>https://www.cnbc.com/2023/06/17/the-japanese-e...</td>\n",
       "      <td>2023-06-18 22:12:00.557919</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>positive</td>\n",
       "      <td>[the, japanese, equity, rally, could, broaden,...</td>\n",
       "      <td>El rally de equidad japonés podría ampliar alg...</td>\n",
       "      <td>Il rally azionario giapponese potrebbe ampliar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ipo market may put pressure on the fed cra...</td>\n",
       "      <td>https://www.cnbc.com/2023/06/16/the-ipo-market...</td>\n",
       "      <td>2023-06-18 22:12:00.557919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>[the, ipo, market, may, put, pressure, on, the...</td>\n",
       "      <td>El mercado de OPI puede ejercer presión sobre ...</td>\n",
       "      <td>Il mercato dell'IPO potrebbe esercitare pressi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  \\\n",
       "ID                                                      \n",
       "0   delta is the most overbought stock on wall str...   \n",
       "1   this compact fund beats the market and provide...   \n",
       "2   blinken meets chinese foreign minister qin gan...   \n",
       "3   the japanese equity rally could broaden out so...   \n",
       "4   the ipo market may put pressure on the fed cra...   \n",
       "\n",
       "                                                  url  \\\n",
       "ID                                                      \n",
       "0   https://www.cnbc.com/2023/06/18/delta-is-the-m...   \n",
       "1   https://www.cnbc.com/2023/06/18/this-compact-f...   \n",
       "2   https://www.cnbc.com/2023/06/18/blinken-meets-...   \n",
       "3   https://www.cnbc.com/2023/06/17/the-japanese-e...   \n",
       "4   https://www.cnbc.com/2023/06/16/the-ipo-market...   \n",
       "\n",
       "                    timestamp  sentiment_score sentiment  \\\n",
       "ID                                                         \n",
       "0  2023-06-18 22:12:00.557919         0.500000   neutral   \n",
       "1  2023-06-18 22:12:00.557919        -0.388889  negative   \n",
       "2  2023-06-18 22:12:00.557919         0.011667  positive   \n",
       "3  2023-06-18 22:12:00.557919        -0.083333  positive   \n",
       "4  2023-06-18 22:12:00.557919         0.000000  positive   \n",
       "\n",
       "                                       relevant_words  \\\n",
       "ID                                                      \n",
       "0   [delta, is, the, most, overbought, stock, on, ...   \n",
       "1   [this, compact, fund, beats, the, market, and,...   \n",
       "2   [blinken, meets, chinese, foreign, minister, q...   \n",
       "3   [the, japanese, equity, rally, could, broaden,...   \n",
       "4   [the, ipo, market, may, put, pressure, on, the...   \n",
       "\n",
       "                                          headline_es  \\\n",
       "ID                                                      \n",
       "0   Delta es el stock más exagerado en Wall Street...   \n",
       "1   Este fondo compacto supera al mercado y propor...   \n",
       "2   Blinken se reúne con el ministro de Relaciones...   \n",
       "3   El rally de equidad japonés podría ampliar alg...   \n",
       "4   El mercado de OPI puede ejercer presión sobre ...   \n",
       "\n",
       "                                          headline_it  \n",
       "ID                                                     \n",
       "0   Delta è lo stock più comprovato di Wall Street...  \n",
       "1   Questo fondo compatto batte il mercato e forni...  \n",
       "2   Blinken incontra il ministro degli Esteri cine...  \n",
       "3   Il rally azionario giapponese potrebbe ampliar...  \n",
       "4   Il mercato dell'IPO potrebbe esercitare pressi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View Data\n",
    "df_headlines.index.name = \"ID\"\n",
    "df_headlines.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-efa96827e8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create file folders (Made it manually but included the code to make it within the code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/headlines\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data'"
     ]
    }
   ],
   "source": [
    "# Create file folders (Made it manually but included the code to make it within the code)\n",
    "os.makedirs(\"data\")\n",
    "os.makedirs(\"data/headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d. Save the headlines DataFrame to a CSV file \n",
    "df_headlines.index = df_headlines.index.rename('ID')\n",
    "df_headlines.to_csv('data/headlines/headlines_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2e, 2f: Stocks Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the stock market data \n",
    "aapl_content=r_aapl.content\n",
    "aapl = pd.read_csv(io.StringIO(aapl_content.decode('utf-8')))\n",
    "msft_content=r_msft.content\n",
    "msft = pd.read_csv(io.StringIO(msft_content.decode('utf-8')))\n",
    "goog_content=r_goog.content\n",
    "goog = pd.read_csv(io.StringIO(goog_content.decode('utf-8')))\n",
    "amzn_content=r_amzn.content\n",
    "amzn = pd.read_csv(io.StringIO(amzn_content.decode('utf-8')))\n",
    "meta_content=r_meta.content\n",
    "meta = pd.read_csv(io.StringIO(meta_content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In prepraration of merge each stock dataframe into one, Lets add the stock name as a column named symbol \n",
    "aapl['symbol']='AAPL'\n",
    "msft['symbol']='MSFT'\n",
    "goog['symbol']='GOOG'\n",
    "amzn['symbol']='AMZN'\n",
    "meta['symbol']='META'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the stocks into one data frame and rename the columns to match the assignment\n",
    "df_stocks=aapl\n",
    "df_stocks.append(msft, ignore_index = True)\n",
    "df_stocks.append(goog, ignore_index = True)\n",
    "df_stocks.append(amzn, ignore_index = True)\n",
    "df_stocks.append(meta, ignore_index = True)\n",
    "dict={\"timestamp\":\"date\", \"open\":\"open_price\", \"high\":\"highest_price\", \"low\":\"lowest_price\", \"close\":\"close_price\"}\n",
    "df_stocks.rename(columns=dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks.index = df_stocks.index.rename('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open_price</th>\n",
       "      <th>highest_price</th>\n",
       "      <th>lowest_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-16 19:00:00</td>\n",
       "      <td>184.92</td>\n",
       "      <td>185.00</td>\n",
       "      <td>184.9200</td>\n",
       "      <td>184.94</td>\n",
       "      <td>9615</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-16 18:00:00</td>\n",
       "      <td>184.93</td>\n",
       "      <td>184.98</td>\n",
       "      <td>184.9200</td>\n",
       "      <td>184.92</td>\n",
       "      <td>5007</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-16 17:00:00</td>\n",
       "      <td>185.02</td>\n",
       "      <td>185.04</td>\n",
       "      <td>184.9200</td>\n",
       "      <td>184.93</td>\n",
       "      <td>123445</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-16 16:00:00</td>\n",
       "      <td>184.92</td>\n",
       "      <td>185.20</td>\n",
       "      <td>184.9015</td>\n",
       "      <td>185.01</td>\n",
       "      <td>15064383</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-16 15:00:00</td>\n",
       "      <td>184.90</td>\n",
       "      <td>185.35</td>\n",
       "      <td>184.2700</td>\n",
       "      <td>185.01</td>\n",
       "      <td>11935261</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  open_price  highest_price  lowest_price  close_price  \\\n",
       "ID                                                                              \n",
       "0   2023-06-16 19:00:00      184.92         185.00      184.9200       184.94   \n",
       "1   2023-06-16 18:00:00      184.93         184.98      184.9200       184.92   \n",
       "2   2023-06-16 17:00:00      185.02         185.04      184.9200       184.93   \n",
       "3   2023-06-16 16:00:00      184.92         185.20      184.9015       185.01   \n",
       "4   2023-06-16 15:00:00      184.90         185.35      184.2700       185.01   \n",
       "\n",
       "      volume symbol  \n",
       "ID                   \n",
       "0       9615   AAPL  \n",
       "1       5007   AAPL  \n",
       "2     123445   AAPL  \n",
       "3   15064383   AAPL  \n",
       "4   11935261   AAPL  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2f. Save Data\n",
    "#os.makedirs(\"data/stocks\")\n",
    "df_stocks.to_csv('data/stocks/stocks_data.csv', index=False,encoding='utf-8')\n",
    "df_stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a) Create a db with the schema for the headlines table and the stocks table\n",
    "db = sql.connect('etl_extended_case.db')\n",
    "c = db.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Create two tables for the headline and stocks data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 21))\n",
      "\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table headlines already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-786fccaccaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrelevant_words\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mheadline_es\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     headline_it TEXT)\"\"\")\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: table headlines already exists"
     ]
    }
   ],
   "source": [
    "c.execute(\"\"\"CREATE TABLE headlines(ID INTEGER PRIMARY KEY NOT NULL, \n",
    "    headline TEXT, \n",
    "    url TEXT,\n",
    "    timestamp TEXT,\n",
    "    sentiment_score REAL,\n",
    "    sentiment TEXT, \n",
    "    relevant_words TEXT,\n",
    "    headline_es TEXT, \n",
    "    headline_it TEXT)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 16))\n",
      "\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table stocks already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f6162134db43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclose_price\u001b[0m \u001b[0mREAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvolume\u001b[0m \u001b[0mINTEGER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     symbol TEXT)\"\"\")\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: table stocks already exists"
     ]
    }
   ],
   "source": [
    "c.execute(\"\"\"CREATE TABLE stocks(ID INTEGER PRIMARY KEY NOT NULL, \n",
    "    date TEXT, \n",
    "    open_price REAL,\n",
    "    highest_price REAL,\n",
    "    lowest_price REAL,\n",
    "    close_price REAL, \n",
    "    volume INTEGER,\n",
    "    symbol TEXT)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data from the CSV files and load into the SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: headlines.ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-305edf5970b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfHeadlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/headlines/headlines_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfHeadlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2613\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2614\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m         )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1826\u001b[0m         )\n\u001b[1;32m   1827\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mexec_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m     def _query_iterator(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_insert_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: headlines.ID"
     ]
    }
   ],
   "source": [
    "dfHeadlines = pd.read_csv('data/headlines/headlines_data.csv')\n",
    "dfHeadlines.to_sql('headlines', db, if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStocks = pd.read_csv('data/stocks/stocks_data.csv')\n",
    "dfStocks.to_sql('stocks', db, if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f512ab44420>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('''SELECT * FROM headlines''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f512ab44420>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('''SELECT * from stocks''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f512ab44420>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data\n",
    "c.execute('''SELECT * FROM headlines LIMIT 5''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f512ab44420>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('''SELECT * FROM stocks LIMIT 5''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
